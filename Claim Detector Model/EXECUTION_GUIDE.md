# Execution Guide: Step-by-Step Certification Workflow

**Purpose:** Practical step-by-step guide to execute the certification workflow

**Prerequisites:** All scripts and documentation in place ‚úÖ

---

## üéØ Phase 1: Stability Confirmation

### Step 1.1: Time-Series Cross-Validation

```bash
cd "Claim Detector Model/claim_detector"
python scripts/time_series_cv.py
```

**What to Check:**
- ‚úÖ CV mean ‚â•0.92
- ‚úÖ CV std ‚â§0.015
- ‚úÖ Each fold improves slightly (monotonic)
- ‚ö†Ô∏è If last fold <0.85 ‚Üí log as temporal drift

**Expected Output:**
```
TIME-SERIES CV RESULTS
Accuracy:  0.92XX ¬± 0.01XX
F1 Score:  0.94XX ¬± 0.01XX
Range:     [0.89XX, 0.94XX]

TARGET ASSESSMENT
‚úÖ CV mean accuracy ‚â•94%: 0.92XX
‚úÖ CV std ‚â§0.015: 0.01XX
```

**If Targets Met:** ‚úÖ Proceed to Step 1.2  
**If Targets Not Met:** ‚ö†Ô∏è Review data quality, consider more regularization

---

### Step 1.2: Feature Audit

```bash
python scripts/feature_audit.py
```

**What to Check:**
- Features with correlation >0.9 (REMOVE)
- Features with correlation 0.7-0.9 (REVIEW)
- High mutual information features (check if spurious)

**Expected Output:**
```
üî¥ REMOVE these features (correlation >0.9):
  - feature_name: 0.95XX

üü° REVIEW these features (correlation 0.7-0.9):
  - feature_name: 0.85XX
```

**Action:** Note features to remove and review

---

### Step 1.3: Feature Optimization

```bash
python scripts/feature_optimization.py
```

**What to Check:**
- ‚úÖ Entropy drop <5% ‚Üí Proceed with optimized set
- ‚ö†Ô∏è Entropy drop 5-10% ‚Üí Review removed features
- ‚ùå Entropy drop >10% ‚Üí Restore some "REVIEW" features

**Expected Output:**
```
ENTROPY ANALYSIS
Baseline entropy:  2.5XXX
Optimized entropy: 2.4XXX
Entropy drop:      0.1XXX (4.XX%)

‚úÖ Entropy drop <5%: Removed noise correctly
   ‚Üí Proceed with optimized feature set
```

**If Entropy Drop <5%:** ‚úÖ Feature schema v1.0 frozen  
**If Entropy Drop >10%:** ‚ö†Ô∏è Restore top 3-5 features from REVIEW list

---

## üéØ Phase 2: Controlled Data Expansion

### Step 2.1: Expand Data

```bash
python scripts/controlled_data_expansion.py
```

**What to Check:**
- ‚úÖ Synthetic ratio ‚â§1.5√ó
- ‚úÖ Label noise ‚â§2%
- ‚úÖ Permutation test p <0.05

**Expected Output:**
```
VALIDATION SUMMARY
‚úÖ All validation checks passed - proceed with retraining

[1/3] Synthetic ratio: 1.50√ó
   ‚úÖ Ratio ‚â§1.5√ó (acceptable)

[2/3] Estimated label noise: 1.XX%
   ‚úÖ Noise ‚â§2% (acceptable)

[3/3] Permutation p-value: 0.0XXX
   ‚úÖ p < 0.05 (proceed with retraining)
```

**If All Checks Pass:** ‚úÖ Proceed to Step 2.2  
**If Checks Fail:** ‚ö†Ô∏è Review expansion method, re-sample

---

### Step 2.2: Retrain on Expanded Data

```bash
python scripts/train_98_percent_model.py
```

**What to Check:**
- ‚úÖ CV mean ‚â•94%
- ‚úÖ CV std ‚â§0.015
- ‚úÖ Bootstrap CI lower ‚â•96%
- ‚úÖ Permutation p <0.05

**Expected Output:**
```
CV Results (25 folds):
  Accuracy:  0.94XX ¬± 0.01XX
  F1 Score:  0.96XX ¬± 0.01XX

Bootstrap 95% CI:
  95% CI:    [0.96XX, 1.0000]
  Status: ‚úÖ PASS (Lower bound ‚â•0.96)

Permutation Test Results:
  P-value:           0.0XXX
  Is significant:   ‚úÖ YES
```

**If Targets Met:** ‚úÖ Proceed to Phase 3  
**If Targets Not Met:** ‚ö†Ô∏è Collect more real data, re-run expansion

---

## üéØ Phase 3: Certification

### Step 3.1: Update Certification Dashboard

1. Open `ML_CERTIFICATION_DASHBOARD.md`
2. Add new row to "Training Iteration History"
3. Update "Last Run" column with new metrics
4. Update "Status" column (‚úÖ/‚ùå/‚ö†Ô∏è)

**Example:**
```markdown
### Iteration 2: After Data Expansion (2025-11-XX)
| Metric | Value | Status |
|--------|-------|--------|
| CV Mean ¬± Std | 0.94XX ¬± 0.01XX | ‚úÖ |
| Bootstrap CI Lower | 0.96XX | ‚úÖ |
| Permutation p-value | 0.0XXX | ‚úÖ |
| Test Accuracy | 0.98XX | ‚úÖ |
| Latency P95 | 35.XXms | ‚úÖ |
```

**Check:** Are all 5 metrics green?  
**If Yes:** ‚úÖ Count toward 3 consecutive green runs  
**If No:** ‚ö†Ô∏è Review and fix issues

---

### Step 3.2: Verify 3 Consecutive Green Runs

**Requirement:** All 5 metrics must be green for 3 consecutive iterations

**Checklist:**
- [ ] Iteration 1: All green?
- [ ] Iteration 2: All green?
- [ ] Iteration 3: All green?

**If All 3 Green:** ‚úÖ **CERTIFIED** - Proceed to Step 3.3  
**If Not:** ‚è≥ Continue training until 3 consecutive green runs

---

### Step 3.3: Export Model Artifacts

**Create export script** (or use existing):

```python
# scripts/export_model_artifacts.py
import pickle
import json
from pathlib import Path
import pandas as pd

def export_artifacts(model, scaler, feature_schema, metrics, version='1.0'):
    base_path = Path('models') / f'v{version}'
    base_path.mkdir(parents=True, exist_ok=True)
    
    # Export model
    with open(base_path / 'model.pkl', 'wb') as f:
        pickle.dump(model, f)
    
    # Export scaler
    with open(base_path / 'scaler.pkl', 'wb') as f:
        pickle.dump(scaler, f)
    
    # Export feature schema
    with open(base_path / 'feature_schema.json', 'w') as f:
        json.dump(feature_schema, f, indent=2)
    
    # Export metadata
    metadata = {
        'version': version,
        'training_date': pd.Timestamp.now().isoformat(),
        'metrics': metrics,
        'feature_count': len(feature_schema['features'])
    }
    with open(base_path / 'model_metadata.json', 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print(f"‚úÖ Artifacts exported to: {base_path}")
    return base_path
```

**Run export:**
```python
# After training completes
from scripts.export_model_artifacts import export_artifacts

export_artifacts(
    model=model.ensemble,
    scaler=model.scaler,
    feature_schema=feature_schema,
    metrics={
        'cv_mean': 0.94XX,
        'cv_std': 0.01XX,
        'bootstrap_lower': 0.96XX,
        'permutation_p': 0.0XXX,
        'test_accuracy': 0.98XX,
        'latency_p95': 35.XX
    },
    version='1.0'
)
```

---

### Step 3.4: Deployability Check

1. Review `DEPLOYABILITY_CHECKLIST.md`
2. Verify all pre-deployment requirements met
3. Run dry-deployment load test (if script available)
4. Verify P99 latency <50ms

**Checklist:**
- [ ] Model artifacts exported
- [ ] Feature schema v1.0 frozen
- [ ] Versioned package created
- [ ] Load test passed
- [ ] P99 latency verified

**If All Pass:** ‚úÖ Ready for deployment  
**If Not:** ‚ö†Ô∏è Complete missing items

---

## üéØ Phase 4: Optional Refinement

### Step 4.1: Check if Refinement Needed

**Trigger:** Test accuracy in 97.7-98.3% range

**If Yes:**
```bash
python scripts/target_refinement.py
```

**What to Check:**
- ‚úÖ Bayesian ensemble improvement
- ‚úÖ Hybrid model improvement
- ‚úÖ Stabilization of accuracy fluctuations

**Expected Output:**
```
REFINEMENT RESULTS
Baseline:        0.98XX
Bayesian:        0.98XX (Œî+0.00XX)
Hybrid:          0.98XX (Œî+0.00XX)

‚úÖ Best method: bayesian (accuracy: 0.98XX)
üéâ Target 98% achieved with refinement!
```

**If Improvement >0.3%:** ‚úÖ Use refined model  
**If Improvement <0.3%:** ‚ö†Ô∏è May need more data

---

## üìä Progress Tracking

### Use This Table to Track Progress:

| Phase | Step | Status | Date | Notes |
|-------|------|--------|------|-------|
| Phase 1 | Time-Series CV | ‚è≥ | - | - |
| Phase 1 | Feature Audit | ‚è≥ | - | - |
| Phase 1 | Feature Optimization | ‚è≥ | - | - |
| Phase 2 | Data Expansion | ‚è≥ | - | - |
| Phase 2 | Retrain | ‚è≥ | - | - |
| Phase 3 | Update Dashboard | ‚è≥ | - | - |
| Phase 3 | Verify 3 Green Runs | ‚è≥ | - | - |
| Phase 3 | Export Artifacts | ‚è≥ | - | - |
| Phase 3 | Deployability Check | ‚è≥ | - | - |
| Phase 4 | Refinement (if needed) | ‚è≥ | - | - |

---

## üö® Troubleshooting

### Issue: CV Mean <0.92
**Solution:** 
- Collect more data
- Increase regularization
- Review feature quality

### Issue: CV Std >0.015
**Solution:**
- Remove unstable features
- Increase regularization
- Use time-series CV

### Issue: Permutation p ‚â•0.05
**Solution:**
- Collect more diverse data
- Reduce model complexity
- Check for label leakage

### Issue: Bootstrap CI Lower <0.96
**Solution:**
- Collect more data
- Improve feature quality
- Reduce model variance

---

## ‚úÖ Completion Criteria

**System is certified when:**
- [x] All 5 metrics green for 3 consecutive runs
- [x] Artifacts exported and versioned
- [x] Deployability checklist complete
- [x] Documentation updated
- [x] Monitoring hooks ready

**You're now ready for production deployment!** üöÄ

---

**Last Updated:** 2025-11-13  
**Next Action:** Execute Phase 1, Step 1.1

