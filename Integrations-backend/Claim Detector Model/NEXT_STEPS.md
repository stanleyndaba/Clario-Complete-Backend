# Next Steps - Model Improvement Roadmap

Based on the validation report and senior ML engineer analysis, here's the prioritized action plan:

---

## ğŸ¯ Immediate Actions (Next 1-2 Days)

### 1. Feature Audit âœ… (Script Ready)
**File:** `scripts/feature_audit.py`

**Run:**
```bash
cd "Claim Detector Model/claim_detector"
python scripts/feature_audit.py
```

**What it does:**
- Calculates correlation matrix vs. target
- Computes mutual information scores
- Identifies features with correlation >0.9 (potential leakage)
- Provides recommendations for feature removal

**Expected output:**
- List of suspicious features
- Correlation and MI scores for all features
- Recommendations for feature pruning

---

### 2. Enhanced Regularization âœ… (Already Applied)

**Changes made:**
- `num_leaves`: 15 â†’ 12
- `min_child_samples`: 10 â†’ 15
- Added `lambda_l2=0.3` (L2 regularization)
- Stricter early stopping (15 rounds)

**Next:** Re-run training to see impact on CV variance

---

### 3. Re-run Training with Enhanced Regularization

```bash
python scripts/train_98_percent_model.py
```

**What to look for:**
- CV mean: Should be similar or slightly lower (more conservative)
- CV std: Should decrease (more stable)
- Permutation p: May improve slightly (less memorization)
- Test accuracy: May decrease slightly (less overfitting)

---

## ğŸ“Š Short-Term Actions (Next 2-4 Weeks)

### 4. Implement Time-Series Cross-Validation

**Current:** Stratified K-fold (may have temporal leakage)

**Recommended:** Blocked time-series CV

**Implementation:**
- Split by date (no future leakage)
- Ensure seller-level grouping (no same seller in train/test)
- Re-run validation

**Expected impact:**
- More realistic CV scores
- Better detection of temporal overfitting

---

### 5. Data Collection Plan

**Target:** +1,000 new samples in 2-4 weeks

**Priority data to collect:**
- âœ… **Non-claimable cases** (currently only 37, need 200+)
- âœ… **Diverse marketplaces** (different regions)
- âœ… **Various SKUs** (different product categories)
- âœ… **Different fee types** (FBA, referral, shipping, etc.)
- âœ… **Time periods** (seasonal variation)
- âœ… **Different seller patterns** (various account behaviors)

**Data logging:**
- Log all claims (especially non-claimable)
- Track prediction accuracy vs. ground truth
- Monitor feature distributions

---

### 6. Feature Simplification (After Audit)

**Based on feature audit results:**
- Remove features with correlation >0.9
- Drop redundant engineered features
- Keep only 10-15 highest-signal features

**Re-train and compare:**
- CV mean should improve (less overfitting)
- CV std should decrease (more stable)
- Permutation p should improve

---

## ğŸš€ Medium-Term Actions (Next 1-2 Months)

### 7. Production Deployment (With Monitoring)

**Deploy current model with:**
- âœ… Speed is production-ready (35ms P95)
- âš ï¸ Set expectations: 88% CV mean, not 98%
- ğŸ“Š Monitor real-world performance

**Monitoring metrics:**
- Prediction accuracy vs. ground truth
- Feature drift detection
- Latency tracking
- Error analysis

---

### 8. Iterative Improvement

**After collecting 2,000+ samples:**
- Re-run full validation suite
- Expected improvements:
  - CV mean: 88% â†’ 94-96%
  - Bootstrap lower: 93.7% â†’ 95-96%
  - Permutation p: 1.0 â†’ <0.05

**At that point:**
- 98% test accuracy will have statistical meaning
- Model can be confidently deployed
- Can push toward 97-98% with more data

---

## ğŸ“ˆ Success Metrics

### Current State
- Test Accuracy: 97.92% âœ… (very close to 98%)
- CV Mean: 88.12% âŒ (needs improvement)
- Bootstrap Lower: 93.70% âŒ (needs improvement)
- Permutation p: 1.0000 âŒ (needs improvement)
- Latency: 35ms âœ… (production-ready)

### Target State (After Data Expansion)
- Test Accuracy: 97-98% âœ…
- CV Mean: 94-96% âœ…
- Bootstrap Lower: 95-96% âœ…
- Permutation p: <0.05 âœ…
- Latency: <100ms âœ…

---

## ğŸ› ï¸ Tools & Scripts

### Available Scripts
1. **`train_98_percent_model.py`** - Main training script with robust validation
2. **`feature_audit.py`** - Feature correlation and leakage detection âœ… Enhanced
3. **`time_series_cv.py`** - Blocked time-series cross-validation âœ… Created

### To Create
1. **`data_collection_monitor.py`** - Track data collection progress
2. **`production_monitor.py`** - Monitor deployed model performance
3. **`explainability_export.py`** - Generate SHAP/LIME artifacts (post-stability)

### Enhanced Regularization (Applied)
- âœ… `feature_fraction`: 0.8 â†’ 0.75 (stochasticity)
- âœ… `min_gain_to_split`: 0.01 (prevent shallow overfits)
- âœ… Early stopping: 20 â†’ 15 rounds (stricter)

---

## ğŸ“ Notes

- **Speed is not the bottleneck** - Focus on data quality/quantity
- **Test accuracy can be misleading** - Always check CV and permutation tests
- **Small datasets cannot reliably achieve 98%** - Need 2k+ samples
- **SMOTE helps but doesn't solve data scarcity** - Need real diverse data

---

## ğŸ¯ Certification Workflow

### Phase 1: Stability Confirmation
1. âœ… Run time-series CV â†’ Check mean â‰¥0.92, std â‰¤0.015
2. âœ… Run feature optimization â†’ Check entropy drop <5%
3. âœ… Freeze feature schema v1.0

### Phase 2: Controlled Expansion
1. âœ… Expand data (synthetic ratio â‰¤1.5Ã—)
2. âœ… Validate (noise â‰¤2%, permutation p <0.05)
3. âœ… Retrain â†’ Target CV mean â‰¥94%

### Phase 3: Certification
1. âœ… Update ML Certification Dashboard
2. âœ… Verify all 5 metrics green for 3 consecutive runs
3. âœ… Export model artifacts
4. âœ… Run deployability checklist

### Phase 4: Optional Refinement
1. âœ… If accuracy 97.7-98.3% â†’ Run target refinement
2. âœ… Bayesian ensembling or LightGBM+TabNet hybrid
3. âœ… Stabilize final 0.3-0.5%

---

## ğŸ“Š New Tools Available

1. **`time_series_cv.py`** - Forward chaining validation âœ…
2. **`feature_optimization.py`** - Entropy-based feature pruning âœ…
3. **`controlled_data_expansion.py`** - Validated data expansion âœ…
4. **`target_refinement.py`** - Advanced ensembling (optional) âœ…
5. **`ML_CERTIFICATION_DASHBOARD.md`** - Track certification metrics âœ…
6. **`DEPLOYABILITY_CHECKLIST.md`** - Pre-deployment validation âœ…

---

**Last Updated:** 2025-11-13  
**Next Review:** After feature audit and data collection progress

---

## ğŸš€ Quick Reference

### Start Here:
1. Read `STRATEGIC_OVERVIEW.md` - High-level strategy
2. Follow `EXECUTION_GUIDE.md` - Step-by-step workflow
3. Track progress in `ML_CERTIFICATION_DASHBOARD.md`

### Key Documents:
- **STRATEGIC_OVERVIEW.md** - Complete framework overview
- **EXECUTION_GUIDE.md** - Detailed step-by-step instructions
- **ML_CERTIFICATION_DASHBOARD.md** - Track certification metrics
- **DEPLOYABILITY_CHECKLIST.md** - Pre-deployment validation

### Key Scripts:
- `time_series_cv.py` - Forward chaining validation
- `feature_optimization.py` - Entropy-based pruning
- `controlled_data_expansion.py` - Validated expansion
- `target_refinement.py` - Advanced ensembling (optional)

