import { Router, Request, Response, NextFunction } from 'express';
import logger from '../utils/logger';
import {
  startAmazonOAuth,
  handleAmazonCallback,
  syncAmazonData,
  getAmazonInventory,
  disconnectAmazon,
  diagnoseAmazonConnection
} from '../controllers/amazonController';
import amazonService from '../services/amazonService';
import { syncJobManager } from '../services/syncJobManager';
import { supabase, supabaseAdmin } from '../database/supabaseClient';
import { authRateLimiter } from '../security/rateLimiter';
import { validateRedirectMiddleware } from '../security/validateRedirect';

const router = Router();

// Note: Rate limiting and redirect validation are applied selectively:
// - Rate limiting: Applied to all auth endpoints
// - Redirect validation: Applied only where redirect URIs are used
// The middleware is applied conditionally based on route requirements

// Wrap handlers to ensure exceptions are surfaced and logged
const wrap = (fn: any) => async (req: any, res: any, next: any) => {
  try { await fn(req, res, next); } catch (err) { logger.error('Amazon route error', { err }); next(err); }
};

// ============================================================================
// CRITICAL: Claims endpoint - MUST BE FIRST to ensure priority registration
// ============================================================================
// This endpoint fetches real claims from Amazon SP-API
// It uses the user ID from middleware (extracted from headers/cookies)
router.get('/claims', async (req: Request, res: Response) => {
  const startTime = Date.now();
  let userId: string = 'demo-user';
  
  try {
    // Extract user ID from middleware (set by userIdMiddleware)
    userId = (req as any).userId || (req as any)?.user?.id || (req as any)?.user?.user_id || 'demo-user';
    
    // Determine sandbox mode
    const spapiUrl = process.env.AMAZON_SPAPI_BASE_URL || '';
    const isSandbox = spapiUrl.includes('sandbox') || process.env.NODE_ENV === 'development';
    
    // Log request with observability
    logger.info('üîç [CLAIMS] Processing claims request', {
      userId,
      isSandbox,
      timestamp: new Date().toISOString(),
      headers: {
        'x-user-id': req.headers['x-user-id'],
        'x-forwarded-user-id': req.headers['x-forwarded-user-id'],
        'authorization': req.headers['authorization'] ? 'present' : 'missing'
      },
      userSource: (req as any).userId ? 'middleware' : 
                   (req as any)?.user?.id ? 'req.user.id' : 
                   'default-demo-user'
    });
    
    // Fetch real claims from Amazon SP-API
    try {
      const claimsResult = await amazonService.fetchClaims(userId);
      const elapsedTime = ((Date.now() - startTime) / 1000).toFixed(2);
      
      // Log successful response with observability
      logger.info('‚úÖ [CLAIMS] Successfully fetched claims from SP-API', {
        userId,
        claimCount: claimsResult.data?.length || 0,
        responseTime: `${elapsedTime}s`,
        isSandbox,
        fromApi: claimsResult.fromApi,
        dataType: claimsResult.dataType,
        source: 'live_mode'
      });
      
      // Return response with claims data (include isMock and mockScenario if present)
      res.status(200).json({
        success: true,
        claims: claimsResult.data || [],
        message: claimsResult.message || `Fetched ${claimsResult.data?.length || 0} claims`,
        source: 'live_mode',
        isSandbox: isSandbox,
        dataType: claimsResult.dataType || (isSandbox ? 'SANDBOX_TEST_DATA' : 'LIVE_DATA'),
        userId: String(userId),
        timestamp: new Date().toISOString(),
        responseTime: `${elapsedTime}s`,
        claimCount: claimsResult.data?.length || 0,
        // Include mock data indicators for frontend
        ...(claimsResult.isMock !== undefined && { isMock: claimsResult.isMock }),
        ...(claimsResult.mockScenario && { mockScenario: claimsResult.mockScenario })
      });
    } catch (spapiError: any) {
      // Handle SP-API errors gracefully
      const elapsedTime = ((Date.now() - startTime) / 1000).toFixed(2);
      
      logger.warn('‚ö†Ô∏è [CLAIMS] SP-API error (returning empty claims)', {
        userId,
        error: spapiError?.message,
        responseTime: `${elapsedTime}s`,
        isSandbox,
        errorType: spapiError?.response?.status ? `HTTP_${spapiError.response.status}` : 'UNKNOWN'
      });
      
      // Return empty claims instead of error (graceful degradation)
      res.status(200).json({
        success: true,
        claims: [],
        message: 'No claims found (SP-API error or empty response)',
        source: 'live_mode_error_fallback',
        isSandbox: isSandbox,
        dataType: isSandbox ? 'SANDBOX_TEST_DATA' : 'LIVE_DATA',
        userId: String(userId),
        timestamp: new Date().toISOString(),
        responseTime: `${elapsedTime}s`,
        error: spapiError?.message || 'Unknown error',
        note: 'SP-API call failed - returning empty claims array'
      });
    }
  } catch (error: any) {
    // CRITICAL SAFETY NET: Even if something catastrophic happens, return success
    const elapsedTime = ((Date.now() - startTime) / 1000).toFixed(2);
    
    logger.error('‚ùå [CLAIMS] Critical error in claims endpoint', {
      userId,
      error: error?.message || String(error),
      stack: error?.stack,
      responseTime: `${elapsedTime}s`
    });
    
    // Force success response - even if headers were sent, try to send JSON
    if (!res.headersSent) {
      try {
        res.status(200).json({
          success: true,
          claims: [],
          message: 'No claims found (internal error)',
          source: 'critical_fallback',
          isSandbox: true,
          dataType: 'SANDBOX_TEST_DATA',
          userId: String(userId),
          timestamp: new Date().toISOString(),
          responseTime: `${elapsedTime}s`,
          error: 'Internal error - safety fallback triggered'
        });
      } catch (finalError: any) {
        // If even this fails, the system is fundamentally broken
        logger.error('‚ùå [CLAIMS] Failed to send response in critical fallback', {
          error: finalError?.message || String(finalError)
        });
      }
    }
  }
});

// Version check endpoint - confirms which code is running
router.get('/claims/version', (req: Request, res: Response) => {
  res.json({
    version: 'phase2-functional-verification-v1',
    deployed: new Date().toISOString(),
    codeVersion: 'phase2-real-claims-flow',
    description: 'Claims endpoint now fetches real data from Amazon SP-API',
    routeOrder: 'claims-registered-first',
    features: {
      realClaimsFetch: true,
      userIdExtraction: true,
      observability: true,
      gracefulDegradation: true
    },
    userIdMiddleware: 'enabled',
    spapiIntegration: 'enabled'
  });
});

// Root Amazon endpoint - start OAuth flow directly (for backward compatibility)
// This handles requests to /api/v1/integrations/amazon
router.get('/', wrap(startAmazonOAuth));

// Apply rate limiting to auth endpoints (before route definitions)
router.use('/auth', authRateLimiter);
router.use('/auth/start', authRateLimiter);
router.use('/auth/callback', authRateLimiter);

// Apply redirect validation to auth callback (state validation only on callback)
router.use('/auth/callback', validateRedirectMiddleware({
  enforceHttps: process.env.NODE_ENV === 'production',
  validateState: true, // Validate state on callback
}));

// Helper function to validate CORS origin
function isValidOrigin(origin: string | undefined): boolean {
  if (!origin) return false;
  
  // Allow all Vercel and Render domains
  const isVercelApp = origin.includes('vercel.app') || origin.includes('vercel.com');
  const isOnRender = origin.includes('onrender.com');
  
  if (isVercelApp || isOnRender) return true;
  
  // Check exact matches
  const allowedOrigins = [
    'https://opside-complete-frontend-4poy2f2lh-mvelo-ndabas-projects.vercel.app',
    'https://opside-complete-frontend-kqvxrzg4s-mvelo-ndabas-projects.vercel.app',
    'https://opside-complete-frontend-nwcors9h1-mvelo-ndabas-projects.vercel.app',
    'https://opside-complete-frontend-6t3yn3p2y-mvelo-ndabas-projects.vercel.app',
    'https://clario-refunds-frontend.onrender.com',
    'https://opside-complete-frontend.onrender.com',
    'http://localhost:8080',
    'http://localhost:5173',
    'http://localhost:3000'
  ];
  
  return allowedOrigins.includes(origin);
}

// CORS preflight handler for auth endpoints
router.options('/auth', (req, res) => {
  const origin = req.headers.origin;
  logger.debug('CORS preflight for /auth', { origin });
  
  if (origin && isValidOrigin(origin)) {
    res.header('Access-Control-Allow-Origin', origin);
    res.header('Access-Control-Allow-Credentials', 'true');
    res.header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
    res.header('Access-Control-Allow-Headers', 'Content-Type, Authorization, X-Requested-With, X-User-Id, X-Frontend-URL, Origin, Referer');
    res.header('Access-Control-Max-Age', '86400');
    res.status(204).send();
  } else {
    logger.warn('CORS preflight rejected for /auth', { origin });
    res.status(403).json({ error: 'CORS: Origin not allowed' });
  }
});

router.options('/auth/start', (req, res) => {
  const origin = req.headers.origin;
  logger.debug('CORS preflight for /auth/start', { origin });
  
  if (origin && isValidOrigin(origin)) {
    res.header('Access-Control-Allow-Origin', origin);
    res.header('Access-Control-Allow-Credentials', 'true');
    res.header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
    res.header('Access-Control-Allow-Headers', 'Content-Type, Authorization, X-Requested-With, X-User-Id, X-Frontend-URL, Origin, Referer');
    res.header('Access-Control-Max-Age', '86400');
    res.status(204).send();
  } else {
    logger.warn('CORS preflight rejected for /auth/start', { origin });
    res.status(403).json({ error: 'CORS: Origin not allowed' });
  }
});

// OAuth routes (with security middleware applied above)
router.get('/auth', wrap(startAmazonOAuth));
router.get('/auth/start', wrap(startAmazonOAuth));
router.get('/auth/callback', wrap(handleAmazonCallback));

// Sandbox callback endpoint - same as regular callback (sandbox uses same OAuth flow)
// SECURITY: Apply rate limiting to sandbox callback too
router.use('/sandbox/callback', authRateLimiter);
router.get('/sandbox/callback', wrap(handleAmazonCallback));
router.post('/sandbox/callback', wrap(handleAmazonCallback));
router.options('/sandbox/callback', (req, res) => {
  // Handle CORS preflight for sandbox callback
  const origin = req.headers.origin;
  logger.debug('CORS preflight for /sandbox/callback', { origin });
  
  if (origin && isValidOrigin(origin)) {
    res.header('Access-Control-Allow-Origin', origin);
    res.header('Access-Control-Allow-Credentials', 'true');
    res.header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
    res.header('Access-Control-Allow-Headers', 'Content-Type, Authorization, X-Requested-With, X-User-Id, X-Frontend-URL, Origin, Referer');
    res.header('Access-Control-Max-Age', '86400');
    res.status(204).send();
  } else {
    logger.warn('CORS preflight rejected for /sandbox/callback', { origin });
    res.status(403).json({ error: 'CORS: Origin not allowed' });
  }
});
router.post('/sync', wrap(syncAmazonData));
router.get('/inventory', wrap(getAmazonInventory));
router.post('/disconnect', wrap(disconnectAmazon));
router.get('/diagnose', wrap(diagnoseAmazonConnection)); // Diagnostic endpoint

// Mock fee endpoint since it was referenced
router.get('/fees', (_, res) => {
  res.json({
    success: true,
    fees: [
      { type: 'referral_fee', amount: 45.50 },
      { type: 'storage_fee', amount: 23.75 }
    ]
  });
});

// Recovery metrics - returns totalAmount, currency, and claimCount
// This endpoint is called by the frontend and should match the expected format
router.get('/recoveries', wrap(async (req: Request, res: Response) => {
  // Extract user ID from middleware (set by userIdMiddleware)
  const userId = (req as any).userId || (req as any)?.user?.id || (req as any)?.user?.user_id || 'demo-user';
  const isSandbox = process.env.AMAZON_SPAPI_BASE_URL?.includes('sandbox') || false;
  
  logger.info('üìä [RECOVERIES] Getting Amazon recoveries summary', {
    userId,
    isSandbox,
    userSource: (req as any).userId ? 'middleware' : 
                 (req as any)?.user?.id ? 'req.user.id' : 
                 'default-demo-user',
    headers: {
      'x-user-id': req.headers['x-user-id'],
      'x-forwarded-user-id': req.headers['x-forwarded-user-id']
    }
  });
  
  try {
    const dbClient = supabaseAdmin || supabase;
    
    // STEP 0: Prefer recoveries table (Agent 8)
    try {
      const { data: recoveryRows, error: recoveryError } = await dbClient
        .from('recoveries')
        .select('id, user_id, expected_amount, actual_amount, reconciliation_status, payout_date, created_at')
        .eq('user_id', userId);

      if (recoveryError) {
        logger.warn('Error querying recoveries table', { error: recoveryError.message, userId });
      } else if (recoveryRows && recoveryRows.length > 0) {
        const recoveryTotals = recoveryRows.reduce(
          (acc, row) => {
            const amount = Number(row.actual_amount ?? row.expected_amount ?? 0);
            acc.total += amount;
            if ((row.reconciliation_status || '').toLowerCase() === 'reconciled') {
              acc.reconciled += 1;
            } else {
              acc.pending += 1;
            }
            return acc;
          },
          { total: 0, reconciled: 0, pending: 0 }
        );

        return res.json({
          totalAmount: Number(recoveryTotals.total.toFixed(2)),
          currency: 'USD',
          claimCount: recoveryRows.length,
          recoveredCount: recoveryTotals.reconciled,
          pendingCount: recoveryTotals.pending,
          source: 'recoveries',
          dataSource: isSandbox ? 'mock_recoveries' : 'live_recoveries',
          message: recoveryTotals.reconciled
            ? `${recoveryTotals.reconciled} recoveries reconciled`
            : 'Recoveries pending reconciliation'
        });
      }
    } catch (recoveryCheckError: any) {
      logger.warn('Failed to read recoveries table', { error: recoveryCheckError.message, userId });
    }
    
    // STEP 1: Use dispute_cases (Agent 7 pipeline)
    try {
      const { data: disputeCases, error: disputeError } = await dbClient
        .from('dispute_cases')
        .select('status, claim_amount, actual_payout_amount, currency')
        .eq('seller_id', userId);

      if (disputeError) {
        logger.warn('Error querying dispute_cases', { error: disputeError.message, userId });
      } else if (disputeCases && disputeCases.length > 0) {
        const disputeTotals = disputeCases.reduce(
          (acc, dispute) => {
            const claimAmount = Number(dispute.claim_amount ?? 0);
            const payoutAmount = Number(dispute.actual_payout_amount ?? 0);
            if ((dispute.status || '').toLowerCase() === 'approved') {
              acc.approvedTotal += payoutAmount || claimAmount;
              acc.approvedCount += 1;
            }
            acc.total += payoutAmount || claimAmount;
            return acc;
          },
          { total: 0, approvedTotal: 0, approvedCount: 0 }
        );

        return res.json({
          totalAmount: Number(disputeTotals.total.toFixed(2)),
          currency: disputeCases[0].currency || 'USD',
          claimCount: disputeCases.length,
          recoveredCount: disputeTotals.approvedCount,
          pendingCount: disputeCases.length - disputeTotals.approvedCount,
          source: 'dispute_cases',
          dataSource: 'agent7_pipeline',
          message: disputeTotals.approvedCount
            ? `${disputeTotals.approvedCount} claims approved`
            : 'Claims submitted - awaiting approval'
        });
      }
    } catch (disputeCheckError: any) {
      logger.warn('Failed to read dispute_cases', { error: disputeCheckError.message, userId });
    }
    
    // STEP 2: Legacy claims table fallback
    try {
      logger.info(`Checking legacy claims table`, { userId });
      const { data: dbClaims, error: dbError } = await dbClient
        .from('claims')
        .select('*')
        .eq('user_id', userId)
        .eq('provider', 'amazon')
        .order('created_at', { ascending: false });
      
      if (dbError) {
        logger.warn('Error querying legacy claims table', { error: dbError.message, userId });
      } else if (dbClaims && dbClaims.length > 0) {
        const totalAmount = dbClaims
          .filter((claim: any) => claim.status === 'approved' || claim.status === 'completed')
          .reduce((sum: number, claim: any) => sum + (parseFloat(claim.amount) || 0), 0);
        const claimCount = dbClaims.length;
        
        logger.info(`Found ${claimCount} legacy claims, total approved: $${totalAmount}`, {
          userId,
          source: 'legacy_claims',
          claimCount,
          totalAmount
        });
        
        return res.json({
          totalAmount,
          currency: 'USD',
          claimCount,
          source: 'legacy_claims',
          dataSource: 'synced_from_spapi_sandbox',
          message: `Found ${claimCount} claims from synced data`
        });
      } else {
        logger.info('No claims found in legacy table', { userId, dbClaimCount: dbClaims?.length || 0 });
      }
    } catch (dbQueryError: any) {
      logger.warn('Error querying legacy claims', { error: dbQueryError.message, userId });
    }
    
    // STEP 3: If no database claims, try fetching from API directly (for real-time data)
    try {
      logger.info(`No database claims found - attempting to fetch from SP-API`, { userId });
      const claimsResult = await amazonService.fetchClaims(userId);
      const claims = claimsResult.data || claimsResult.claims || [];
      
      logger.info(`API fetch result:`, {
        hasData: !!claimsResult,
        claimsType: Array.isArray(claims) ? 'array' : typeof claims,
        claimsLength: Array.isArray(claims) ? claims.length : 'N/A',
        claimsResultKeys: claimsResult ? Object.keys(claimsResult) : [],
        isSandbox: claimsResult.isSandbox || false,
        dataType: claimsResult.dataType || 'unknown'
      });
      
      if (Array.isArray(claims) && claims.length > 0) {
        const totalAmount = claims
          .filter((claim: any) => claim.status === 'approved')
          .reduce((sum: number, claim: any) => sum + (parseFloat(claim.amount) || 0), 0);
        const claimCount = claims.length;
        
        logger.info(`Found ${claimCount} claims from API, total approved: $${totalAmount}`, {
          userId,
          source: 'api',
          claimCount,
          totalAmount,
          isSandbox: claimsResult.isSandbox || false
        });
        
        return res.json({
          totalAmount,
          currency: 'USD',
          claimCount,
          source: 'api',
          dataSource: claimsResult.isSandbox ? 'spapi_sandbox' : 'spapi_production',
          message: `Found ${claimCount} claims from API`
        });
      } else {
        logger.info('No claims found in API response (empty array or no data)', {
          userId,
          claimsResultType: typeof claimsResult,
          claimsResultKeys: claimsResult ? Object.keys(claimsResult) : [],
          claimsType: typeof claims,
          claimsIsArray: Array.isArray(claims),
          isSandbox: claimsResult?.isSandbox || false,
          note: claimsResult?.note || 'No data available'
        });
      }
    } catch (error: any) {
      logger.error(`Error fetching claims from API:`, {
        error: error.message,
        stack: error.stack,
        userId
      });
    }
    
    // Trigger sync in the background if no data was returned
    try {
      logger.info('No recoveries found - attempting to trigger automatic sync', { userId });
      syncJobManager.startSync(userId).then((result) => {
        logger.info('Successfully triggered automatic sync from recoveries endpoint', { 
          userId, 
          syncId: result.syncId 
        });
      }).catch((syncError: any) => {
        if (syncError.message && syncError.message.includes('already in progress')) {
          logger.info('Sync already in progress, skipping automatic trigger', { userId });
        } else {
          logger.warn('Failed to trigger automatic sync from recoveries endpoint', {
            userId,
            error: syncError.message
          });
        }
      });
    } catch (syncTriggerError: any) {
      logger.warn('Error triggering sync from recoveries endpoint', {
        userId,
        error: syncTriggerError.message
      });
    }
    
    logger.info('No claims found, returning zeros - sync may be in progress', {
      userId,
      isSandbox,
      syncTriggered: true
    });
    return res.json({
      totalAmount: 0.0,
      currency: 'USD',
      claimCount: 0,
      source: 'none',
      dataSource: isSandbox ? 'spapi_sandbox_empty' : 'spapi_production_empty',
      message: 'No data found. Syncing your Amazon account... Please refresh in a few moments.',
      needsSync: true,
      syncTriggered: true,
      isSandbox
    });
  } catch (error: any) {
    // Log error but still return a valid response (never return 500 for empty data)
    logger.error('Error in recoveries endpoint (returning empty response):', {
      error: error?.message || String(error),
      userId,
      isSandbox
    });
    return res.json({
      totalAmount: 0.0,
      currency: 'USD',
      claimCount: 0,
      source: 'none',
      dataSource: isSandbox ? 'spapi_sandbox_empty' : 'spapi_production_empty',
      message: 'No data found. Please sync your Amazon account first.',
      needsSync: true,
      isSandbox: isSandbox
    });
  }
}));

// GET /api/v1/integrations/amazon/upcoming-payments
// Get upcoming payments from filed/approved claims
router.get('/upcoming-payments', wrap(async (req: Request, res: Response) => {
  const userId = (req as any).userId || (req as any)?.user?.id || (req as any)?.user?.user_id || 'demo-user';
  
  logger.info('üìä [UPCOMING PAYMENTS] Getting upcoming payments', { userId });
  
  try {
    // Query dispute_cases for filed/approved claims with expected payout dates
    const { data: disputeCases, error } = await supabase
      .from('dispute_cases')
      .select('id, seller_id, claim_amount, currency, status, expected_payout_date, created_at, dispute_type')
      .eq('seller_id', userId)
      .in('status', ['filed', 'approved', 'pending'])
      .not('expected_payout_date', 'is', null)
      .order('expected_payout_date', { ascending: true });
    
    if (error) {
      logger.error('‚ùå [UPCOMING PAYMENTS] Failed to fetch dispute cases', { error: error.message, userId });
      return res.status(500).json({ 
        success: false, 
        error: 'Failed to fetch upcoming payments',
        recoveries: [] 
      });
    }
    
    // Transform to match frontend expected format
    const recoveries = (disputeCases || []).map((dc: any) => ({
      id: dc.id,
      claim_id: dc.id,
      type: dc.dispute_type || 'unknown',
      status: dc.status,
      amount: parseFloat(dc.claim_amount?.toString() || '0'),
      currency: dc.currency || 'USD',
      created_at: dc.created_at,
      expected_payout_date: dc.expected_payout_date,
      // Map to frontend field names
      guaranteedAmount: parseFloat(dc.claim_amount?.toString() || '0'),
      expectedPayoutDate: dc.expected_payout_date,
      created: dc.created_at
    }));
    
    logger.info('‚úÖ [UPCOMING PAYMENTS] Found upcoming payments', { 
      userId, 
      count: recoveries.length 
    });
    
    return res.json({
      success: true,
      recoveries: recoveries,
      total: recoveries.length
    });
    
  } catch (error: any) {
    logger.error('‚ùå [UPCOMING PAYMENTS] Error', { error: error.message, userId });
    return res.status(500).json({ 
      success: false, 
      error: 'Internal server error',
      recoveries: [] 
    });
  }
}));

export default router;
