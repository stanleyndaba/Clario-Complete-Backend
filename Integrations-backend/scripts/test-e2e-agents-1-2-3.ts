/**
 * End-to-End Test: Agents 1, 2, 3 Pipeline
 * Tests the complete flow: OAuth â†’ Data Sync â†’ Claim Detection
 * 
 * Agent 1: Zero Agent Layer (OAuth - simulated)
 * Agent 2: Data Sync (fetches/generates data, normalizes, sends to Python API)
 * Agent 3: Claim Detection (Python Discovery Agent)
 */

import 'dotenv/config';
import { supabase, supabaseAdmin } from '../src/database/supabaseClient';
import logger from '../src/utils/logger';

interface TestResult {
  name: string;
  passed: boolean;
  error?: string;
  details?: any;
}

const testResults: TestResult[] = [];
const testData: {
  userId?: string;
  syncId?: string;
} = {};

function logTest(name: string, passed: boolean, error?: string, details?: any) {
  testResults.push({ name, passed, error, details });
  if (passed) {
    logger.info(`âœ… ${name}`, details || {});
  } else {
    logger.error(`âŒ ${name}`, { error, details });
  }
}

async function setupTestUser() {
  logger.info('\nðŸ“‹ Setting up test user (simulating Agent 1 OAuth)...');

  try {
    const client = supabaseAdmin || supabase;
    testData.userId = `test-e2e-a123-${Date.now()}`;

    // Simulate Agent 1: Create a connected Amazon token entry
    // In production, this would come from OAuth callback
    const { error: tokenError } = await client
      .from('amazon_tokens')
      .insert({
        user_id: testData.userId,
        seller_id: `SELLER-${Date.now()}`,
        access_token: 'mock-access-token-for-testing',
        refresh_token: 'mock-refresh-token-for-testing',
        token_expiry: new Date(Date.now() + 3600000).toISOString(), // 1 hour from now
        marketplace_id: 'ATVPDKIKX0DER',
        created_at: new Date().toISOString(),
        updated_at: new Date().toISOString()
      });

    if (tokenError) {
      // Token table might not exist in test env, continue anyway
      logger.warn('Could not create amazon_tokens entry (may not exist)', { error: tokenError.message });
    }

    logTest('Agent 1: OAuth Setup (Simulated)', true, undefined, { userId: testData.userId });
    return true;
  } catch (error: any) {
    logTest('Agent 1: OAuth Setup (Simulated)', false, error.message);
    return false;
  }
}

async function testAgent2DataSync() {
  logger.info('\nðŸ”„ Testing Agent 2: Data Sync...');

  try {
    // Import Agent 2 service
    const { default: agent2DataSyncService } = await import('../src/services/agent2DataSyncService');

    // Run Agent 2 sync (will use mock data since no real Amazon connection)
    logger.info('Starting Agent 2 data sync...', { userId: testData.userId });
    const syncResult = await agent2DataSyncService.syncUserData(testData.userId!);

    testData.syncId = syncResult.syncId;

    logger.info('Agent 2 sync result:', {
      success: syncResult.success,
      syncId: syncResult.syncId,
      isMock: syncResult.isMock,
      mockScenario: syncResult.mockScenario,
      summary: syncResult.summary,
      errors: syncResult.errors
    });

    // Log detailed normalized data counts
    logger.info('Agent 2 normalized data:', {
      ordersCount: syncResult.normalized?.orders?.length || 0,
      shipmentsCount: syncResult.normalized?.shipments?.length || 0,
      returnsCount: syncResult.normalized?.returns?.length || 0,
      settlementsCount: syncResult.normalized?.settlements?.length || 0,
      inventoryCount: syncResult.normalized?.inventory?.length || 0,
      claimsCount: syncResult.normalized?.claims?.length || 0
    });

    // Check if any data was generated
    const hasData = (syncResult.summary?.ordersCount || 0) > 0 ||
                   (syncResult.summary?.shipmentsCount || 0) > 0 ||
                   (syncResult.summary?.returnsCount || 0) > 0;

    if (!hasData) {
      logTest('Agent 2: Data Sync', false, 'No data generated by mock generator', { summary: syncResult.summary });
      return false;
    }

    // Sample some normalized data to verify structure
    if (syncResult.normalized?.orders?.length > 0) {
      const sampleOrder = syncResult.normalized.orders[0];
      logger.info('Sample normalized order:', {
        order_id: sampleOrder.order_id,
        total_amount: sampleOrder.total_amount,
        total_fees: sampleOrder.total_fees,
        items: sampleOrder.items?.length || 0
      });
    }

    if (syncResult.normalized?.shipments?.length > 0) {
      const sampleShipment = syncResult.normalized.shipments[0];
      logger.info('Sample normalized shipment:', {
        shipment_id: sampleShipment.shipment_id,
        items: sampleShipment.items?.length || 0,
        missing_quantity: sampleShipment.missing_quantity,
        status: sampleShipment.status
      });
    }

    if (syncResult.normalized?.returns?.length > 0) {
      const sampleReturn = syncResult.normalized.returns[0];
      logger.info('Sample normalized return:', {
        return_id: sampleReturn.return_id,
        items: sampleReturn.items?.length || 0,
        refund_amount: sampleReturn.refund_amount
      });
    }

    logTest('Agent 2: Data Sync', syncResult.success, syncResult.errors?.join(', '), {
      syncId: syncResult.syncId,
      summary: syncResult.summary,
      isMock: syncResult.isMock
    });

    return syncResult.success;
  } catch (error: any) {
    logTest('Agent 2: Data Sync', false, error.message);
    return false;
  }
}

async function checkAgent3DetectionResults() {
  logger.info('\nðŸ” Checking Agent 3: Claim Detection Results...');

  try {
    const client = supabaseAdmin || supabase;

    // Check detection_results table for claims created by Agent 3
    const { data: detections, error: detectionsError } = await client
      .from('detection_results')
      .select('*')
      .eq('seller_id', testData.userId!)
      .order('created_at', { ascending: false })
      .limit(20);

    if (detectionsError) {
      logTest('Agent 3: Claim Detection', false, detectionsError.message);
      return false;
    }

    logger.info('Detection results found:', {
      count: detections?.length || 0,
      syncId: testData.syncId
    });

    if (detections && detections.length > 0) {
      // Log sample detections
      for (const detection of detections.slice(0, 3)) {
        logger.info('Sample detection:', {
          id: detection.id,
          anomaly_type: detection.anomaly_type,
          confidence_score: detection.confidence_score,
          estimated_value: detection.estimated_value,
          status: detection.status
        });
      }

      // Count by anomaly type
      const byType: Record<string, number> = {};
      for (const d of detections) {
        byType[d.anomaly_type] = (byType[d.anomaly_type] || 0) + 1;
      }
      logger.info('Detections by type:', byType);

      // Count by confidence level
      const highConf = detections.filter(d => d.confidence_score >= 0.85).length;
      const medConf = detections.filter(d => d.confidence_score >= 0.5 && d.confidence_score < 0.85).length;
      const lowConf = detections.filter(d => d.confidence_score < 0.5).length;
      logger.info('Detections by confidence:', { high: highConf, medium: medConf, low: lowConf });

      logTest('Agent 3: Claim Detection', true, undefined, {
        totalDetections: detections.length,
        byType,
        byConfidence: { high: highConf, medium: medConf, low: lowConf }
      });
      return true;
    } else {
      logTest('Agent 3: Claim Detection', false, 'No detection results found - claims not being created');
      return false;
    }
  } catch (error: any) {
    logTest('Agent 3: Claim Detection', false, error.message);
    return false;
  }
}

async function checkDetectionQueue() {
  logger.info('\nðŸ“‹ Checking detection_queue status...');

  try {
    const client = supabaseAdmin || supabase;

    const { data: queue, error: queueError } = await client
      .from('detection_queue')
      .select('*')
      .eq('seller_id', testData.userId!)
      .order('created_at', { ascending: false })
      .limit(5);

    if (queueError) {
      logger.warn('Could not check detection_queue', { error: queueError.message });
      return;
    }

    if (queue && queue.length > 0) {
      for (const entry of queue) {
        logger.info('Detection queue entry:', {
          id: entry.id,
          status: entry.status,
          sync_id: entry.sync_id,
          payload: entry.payload
        });
      }
    } else {
      logger.info('No detection_queue entries found');
    }
  } catch (error: any) {
    logger.warn('Error checking detection_queue', { error: error.message });
  }
}

async function testPrepareClaimsDirectly() {
  logger.info('\nðŸ§ª Testing prepareClaimsFromNormalizedData directly...');

  try {
    // Import Agent 2 service to access the method
    const { Agent2DataSyncService } = await import('../src/services/agent2DataSyncService');
    const agent2 = new Agent2DataSyncService();

    // Create sample normalized data that should generate claims
    const sampleData = {
      orders: [
        {
          order_id: 'TEST-ORDER-001',
          total_amount: 100.00,
          total_fees: 5.00, // This should trigger a claim
          order_date: new Date().toISOString(),
          marketplace_id: 'US'
        }
      ],
      shipments: [
        {
          shipment_id: 'TEST-SHIP-001',
          items: [
            { sku: 'SKU-001', asin: 'B001', quantity: 10, price: 15.00 }
          ],
          missing_quantity: 2, // This should trigger a claim
          shipped_date: new Date().toISOString(),
          status: 'partial'
        }
      ],
      returns: [
        {
          return_id: 'TEST-RET-001',
          items: [
            { sku: 'SKU-002', asin: 'B002', quantity: 1, refund_amount: 25.00 }
          ],
          refund_amount: 25.00, // This should trigger a claim
          returned_date: new Date().toISOString()
        }
      ],
      settlements: [
        {
          settlement_id: 'TEST-SETTLE-001',
          amount: 500.00,
          fees: 50.00, // This should trigger a claim
          settlement_date: new Date().toISOString()
        }
      ]
    };

    // Access private method via type assertion
    const prepareClaimsMethod = (agent2 as any).prepareClaimsFromNormalizedData.bind(agent2);
    const claims = prepareClaimsMethod(sampleData, testData.userId);

    logger.info('Claims generated from sample data:', {
      totalClaims: claims.length,
      claimTypes: claims.map((c: any) => c.category)
    });

    if (claims.length > 0) {
      for (const claim of claims.slice(0, 3)) {
        logger.info('Sample claim:', {
          claim_id: claim.claim_id,
          category: claim.category,
          subcategory: claim.subcategory,
          amount: claim.amount,
          reason_code: claim.reason_code
        });
      }
      logTest('Direct prepareClaimsFromNormalizedData', true, undefined, { claimsGenerated: claims.length });
      return true;
    } else {
      logTest('Direct prepareClaimsFromNormalizedData', false, 'No claims generated from sample data');
      return false;
    }
  } catch (error: any) {
    logTest('Direct prepareClaimsFromNormalizedData', false, error.message);
    return false;
  }
}

async function cleanup() {
  logger.info('\nðŸ§¹ Cleaning up test data...');

  try {
    const client = supabaseAdmin || supabase;

    if (testData.userId) {
      // Clean up detection_results
      await client
        .from('detection_results')
        .delete()
        .eq('seller_id', testData.userId);

      // Clean up detection_queue
      await client
        .from('detection_queue')
        .delete()
        .eq('seller_id', testData.userId);

      // Clean up amazon_tokens
      await client
        .from('amazon_tokens')
        .delete()
        .eq('user_id', testData.userId);

      logger.info('Cleanup completed', { userId: testData.userId });
    }
  } catch (error: any) {
    logger.warn('Cleanup error (non-critical)', { error: error.message });
  }
}

async function printSummary() {
  logger.info('\n' + '='.repeat(60));
  logger.info('ðŸ“Š TEST SUMMARY: Agents 1-2-3 E2E Pipeline');
  logger.info('='.repeat(60));

  const passed = testResults.filter(t => t.passed).length;
  const failed = testResults.filter(t => !t.passed).length;

  for (const result of testResults) {
    const status = result.passed ? 'âœ… PASS' : 'âŒ FAIL';
    logger.info(`${status}: ${result.name}`);
    if (!result.passed && result.error) {
      logger.info(`   Error: ${result.error}`);
    }
  }

  logger.info('='.repeat(60));
  logger.info(`Total: ${testResults.length} | Passed: ${passed} | Failed: ${failed}`);
  logger.info('='.repeat(60));

  return failed === 0;
}

async function main() {
  logger.info('ðŸš€ Starting Agents 1-2-3 E2E Test Pipeline');
  logger.info('='.repeat(60));

  try {
    // Test 1: Setup (simulates Agent 1 OAuth)
    const setupOk = await setupTestUser();
    if (!setupOk) {
      logger.error('Setup failed, aborting tests');
      await printSummary();
      process.exit(1);
    }

    // Test 2: Direct claim preparation test (validates logic)
    await testPrepareClaimsDirectly();

    // Test 3: Agent 2 Data Sync (includes Agent 3 call)
    const syncOk = await testAgent2DataSync();

    // Give Agent 3 (Python API) time to process - need longer wait for async batches
    if (syncOk) {
      logger.info('Waiting 15 seconds for Agent 3 to process all batches...');
      await new Promise(resolve => setTimeout(resolve, 15000));
    }

    // Test 4: Check Agent 3 results
    await checkAgent3DetectionResults();

    // Additional diagnostics
    await checkDetectionQueue();

    // Cleanup
    await cleanup();

    // Print summary
    const allPassed = await printSummary();
    process.exit(allPassed ? 0 : 1);

  } catch (error: any) {
    logger.error('Test pipeline error', { error: error.message });
    await cleanup();
    await printSummary();
    process.exit(1);
  }
}

main();

